tensorboard --logdir=unsup-<name>
Vai a http://localhost:6006 nel tuo browser per vedere le visualizzazioni.


tensor = tensore, è una struttura dati generale definita in un singolo spazio vettoriale
flow = flusso che viene eseguito per il calcolo di operazioni complesse

Tensorflow viene utilizzato per il calcolo di operazioni che coinvolgono tensori, rappresentazioni generiche di vettori e matrici

I tensori sono rappresentati come array n-dimensionali di datatypes base (int, string, ecc)

Il tensore puo essere una variabile (tf.variable) o una costante (tf.constant)

Ogni elemento in un tensor condivide il proprio data type

un grafo è costituito da tensori, che gestiranno i dati, e dalle operazioni compiuti su di essi.

All'interno del modello supervisionato Graphsage, vengono inizialmente creati dei placheholders, cioè nodi che verranno alimentati dinamicamente con dati esterni durante l'addestramento e la validazione.

Per configurare le informazioni di adiacenza, viene creato un placeholder per le informazioni di adiacenza del grafo e una variabile per memorizzare le informazioni di adiacenza (non addestrabile perchè rappresenta la struttura del grafo, non i parametri del modello)
	grazie alla matrice di adiacenza andremo a definire la struttura del grafo (i nodi collegati)
	la matrice di adiacenza aiuta il modello a capire quali sono i nodi vicini e quindi quali caratteristiche possono essere aggregate per ogni nodo (vengono aggregate le caratteristiche dei nodi vicini diretti)
	il motivo per il quale viene utilizzato un placeholder (adj_info_ph) e una variabile (adj_info) è che in questo modo la matrice di adiacenza può cambiare in modo dinamico, per via della presenza dei mini-batch (sottoinsieme di nodi) oppure utile per quando si passa da addestramento a validazione, per avere diverse strutture di adiacenza.
	problemi risolti: grazie alla matrice di adiacenza non dobbiamo processare il grafo in un singolo passaggio, con tf.assign si passa tranquillamente dal grafo di addestramento a quello di validazione, rende semplice sapere quali sono i nodi vicini.

viene creata una nuova sessione con determinate configurazioni

in sess.run vengono inizializzate le variabili fornendo i dati al placheholder (feed_dict)
	il feed_dict mappa i placeholders definiti nel modello ai dati effettivi da utilizzare in quella specifica iterazione, i dati in questione possono essere le etichette dei nodi del batch corrente o anche la matrice di adiacenza 

con tf.assign viene assegnato una nuova matrice di adiacenza relativo ad un nuovo minibatch. 
	per ogni epoca si fa sia la fase di addestramento che quella di validazione, una fase dietro l'altra.



LETTURA GRAFO
- nodi blu: (adj_info, uniformneighbor) rappresentano placeholders e variabili, con anche la matrice di adiacenza.
	il nodo adj_info rappresenta le informazioni di adiacenza del grafo ed è collegato a operazioni che permettono di aggiornare queste informazioni.
	i nodi uniformneighbor rappresentano la selezione dei vicini dei nodi da aggregare.
- nodi arancioni: (meanaggregator) operazioni di aggregazione, cioè calcola la media dei vicini di un nodo per aggiornare le rappresentazioni.
- nodi verdi: (reshape, variable) operazioni di riformattazione dei tensori e le variabili rappresentano parametri che il modello apprende durante l'addestramento.
- nodi grigi: (logistic_loss, dense_1) rappresentano il calcolo della funzione di loss e strati densi. 
	dense_1 è un layer fully connected che applica un insieme di pesi ai dati aggregati per fare una previsione
	dopo che la perdita viene calcolata, viene eseguito il calcolo del gradiente che ritorna indietro lungo gli archi del grafo verso i nodi responsabili dei pesi, quindi con l'ottimizzatore Adam, vengono aggiornati i pesi (prima di Adam i gradienti vengono limitati a un intervallo con "clip_by_value")
- nodo Adam rappresenta l'algoritmo di ottimizzazione Adam, usato per aggiornare i pesi del modello sulla base della perdita calcolata
- archi: rappresentano il flusso di dati tra i nodi e i tensori attraversano questi archi durante l'addestramento.

- mul[0-10]: moltiplicazione tra due tensori, usata per aggiornare i pesi
- batch1: è il minibatch di input dell'addestramento
- embedding_lookup_1: per ottenere l'embedding di un determinato nodo (l'embedding è un vettore che rappresenta le caratteristihe di un nodo)
- embedding_lookup_1/axis: definisce l'asse su cui deve avvenire la ricerca degli embedding
- mean: calcola la media della loss su tutti gli esempi nel batch (dopo aver calcolato la logistic_loss)
- add[0-6]: operazione di somma, usata dopo aver calcolato la media per sommare diversi contributi alla perdita complessiva (gradienti o correzioni?)
Graphsage, supervised_train.

BATCH
un insieme di dati che vengono elaborati in un singolo passo di addestramento. Usando i batch si sfrutta l'efficienza computazionale delle operazioni vettoriali e permette di ridurre la varianza della stima del gradiente -> addestramento più stabile.

MINIBATCH
un sottoinsieme di un batch. L'addestramento avviene su questi minibatch ed è una via di mezzo tra l'addestramento che utilizza l'intero set di dati (batch) e l'addestramento che utilizza un singolo esempio alla volta. 
Nel codice, il minibatch, viene creato con NodeMinibatchIterator [riga 139 - supervised_train.py] e con la funzione next_minibatch_feed_dict [riga 270] viene fornito il prossimo minibatch di dati con le etichette corrispondenti. 


tf.app.run(): avvia l'esecuzione del programma tensorflow[v1.8] (costruisce un grafo computazionale) e procede con la funzione main(). Inoltre esegue il parsing degli argomenti.

main: carica i dati di training (gestiti con FLAGS) e avvia l'addestramento (train()). 

train: 
	vengono caricati i dati (G, features, id_map, class_map).
	verifica se i valori di class_map sono liste e calcola il numero di classi.
	se i nodi hanno delle features, viene aggiunta una riga di zeri alla matrice delle features (per gestire i nodi che non hanno features assegnate)
	context_pairs vengono incluse nell'argomento se random_context è su true
	placeholders sono variabili speciali utilizzate in tensorflow per rappresentare degli input.
	minibatch, un iteratore che seleziona un sottoinsieme dei nodi e delle loro connessioni per ogni passo di addestramento. Ha diversi parametri.
	adj_info_ph, placeholder per la matrice  di adiacenza, rappresenta le connessioni tra i nodi.
	adj_info variabile che rappresenta la matrice di adiacenza (no addestrabile)

	Viene scelto il modello in base al parametro FLAGS.model
	1. graphsage_mean:
		sampler: campionatore che seleziona i vicini dei nodi in modo casuale, in base a adj_info
		Layer Infos: vengono creati oggetti che rappresentano informazioni per ciascun layer del modello
		modello: viene creato il modello usando la classe SupervisedGraphsage (importato da supervised_models), con tutti i dati in questione.
	2. gcn (Graph Convolutional Network):
		differenze col precedente: l'uso dell'aggregatore specifico "gcn" come parametro del modello e i layer usano dimensioni doppie.
	3. Altri modelli (graphsage_seq, graphsage_maxpool, graphsage_meanpool):
		processo uguale al primo, quello che cambio èil tipo di aggregatore utilizzato per il modello
	Configurazione di TF: con tf.ConfigProto e altre cose.

	Inizializzazione della sessione di TensorFlow: viene creata una sessione TF sess, merge dei tensori di riepilogo definiti in precedenza e viene creato un writer per il log.
	Inizializzazione delle variabili: sia quelle globali e le variabili di adiacenza del grafo.
	



	Ciclo di addestramento e validazione: avviene per un numero definito di epoche (flags)
	1. inizializzazione delle variabili per l'addestramento (step totali, tempo medio e costo di validazione per epoca)
	2. matrici di adiacenza impostate per allenamento e validazione
	3. il dataset (minibatch) viene mescolato così vengono forniti in ordine casuale.

	4. Nel ciclo principale di addestramento (quindi per ogni minibatch):
		viene estratto il prossimo minibatch e crea il dizionario feed_dict per passare i dati al modello
		aggiunge la possibilità di dropout al feed_dict.
		sess.run: esegue il grafo di addestramento focalizzandosi sulla classe model (qua viene calcolata la perdita (LOSS) del minibatch corrente e salvata su train_cost), 
			model.opt_op: esegue un passo di ottimizzazione che minimizza la funzione di perdita. Come funziona? Dopo aver calcolato la loss, vengono calcolati i gradienti rispetto ai parametri del modello (compute_gradients() in supervised_models.py). Successivamente viene eseguito il gradient clipping (clipped_grads_and_vars), per far rimanere il gradient all'interno di un certo limite per evitare aggiornamenti drastici dei pesi, che potrebbero rovinare il training. Successivamente viene fatto un controllo se i gradienti sono None, cioè non esistono per alcune variabili. Il primo gradiente della lista viene quindi salvato su self.grad. Infine con self.opt_op, l'ottimizzatore usa i gradienti per aggiornare i parametri del modello e ridurre la funzione di perdita (eseguito da apply_gradients() dell'ottimizzatore).
			model.loss: calcola la train loss per il batch attuale (spiegata giù)
			model.preds: fornisce le predizioni del modello per il batch attuale. Come funziona? Le predizioni del modello vengono generate con la funzione self.predict(), che restituisce il risultato di una funzione di attivazione (nel nostro caso la sigmoid) applicata ai valori grezzi prodotti dal modello (cioè i self.node_preds).
	
	5. validazione: ogni x minibatch, viene eseguita una validazione (la x è impostata tramite la flag "validate_iter") 
		matrice di adiacenza impostata
		incremental_evaluate() per la valutazione incrementale su tutto il dataset di validazione, usata quando il batch di validazione non ha un limite fisso
		con evaluate(), valutazione diretta con batch di validazione di dimensione fissa, calcolo la loss, f1_micro e macro della validazione
		ripristina la matrice di adiacenza ai dati di addestramento
		Accumula la perdita di validazione nel costo totale dell'epoca corrente. 
	6. ogni x interazioni (impostata da una flag) vengono calcolate f1_micro e f1_macro usando la funzione calc_f1.
	fine addestramento

	vengono salvate le metriche e tempi di validazione e di test







Considerando il modello di tipo graphsage_mean, vediamo nel dettaglio il calcolo delle metriche.

Metriche di addestramento (train)
LOSS: calcolata quando procede con l'operazione sess.run e che include model.loss. Viene calcolata in due fasi principali:
	1. Perdita dovuta alla regolarizzazione L2: aggiunge una componente di regolarizzazione al modello per prevenire l'overfitting, penalizzando i pesi di grande magnitudine. La regolarizzazione L2 viene applicata alle variabili (i pesi) degli aggregatori del modello e alle variabili (i pesi) utilizzati per la predizione finale. la l2_loss è il quadrato della norma L2 (somma dei quadrati dei valori del tensore) e viene moltiplicato per un fattore di regolarizzazione (un flag) che controlla quanto influisce la regolarizzazione nel calcolo della perdita complessiva.
	2. Perdita di classificazione: 
		a. per classificazione binaria  o multilabel (se sigmoid_loss è True), viene calcolata la perdita con tf.nn.sigmoid_cross_entropy_with_logits(logits, labels) (cross-entropy per ogni campione): logit sono le uscite grezze del modello non ancora passate attraverso una funzione di attivazione (come la sigmoide che comprime i logits in un intervallo tra 0 e 1), le labels sono le etichette fornite dal placeholder. Infine con tf.reduce_mean() viene fatta la media  della perdita su tutti i campioni del minibatch.
		b. per classificazione multiclass: viene utilizzata la funzione softmax_cross_entropy_with_logits, che calcola la cross-entropy per la classificazione multiclasse. Le label rappresentano etichette reali, che sono fornite come one-hot. tf.reduce_mean(): La perdita di cross-entropy viene mediata su tutto il batch.

	Infine viene aggiunto il valore corrente di self.loss ai log di TensorBoard, per monitorare l'andamento della perdita durante l'allenamento. Viene creato un riassunto scalare del valore self.loss, visualizzabile con TensorBoard.

F1_MICRO e F1_MACRO: 
	Viene usata direttamente la funzione calc_f1:
		se non è sigmoid (quindi è softmax per la classificazione multiclasse) si convertono le predizioni e le etichette vere negli indici delle classi predette usando np.argmax.
		se è sigmoid (classificazione multi-label), si applica una soglia di 0.5 per decidere se un'etichetta è attiva (1) o no (0).
		usa metrics.f1_score() dalla libreria sklearn per calcolare le metriche f1 micro e macro.


Metriche di validazione: calcolate all'interno delle funzioni incremental_evaluate o evaluate.
	Funzione evaluate:
		imposta timer
		crea il feed_dict che contiene i dati di input necessari per la validazione e ottiene anche le labels corrispondenti al minibatch
		con sess_run() calcola le predizioni e la perdita (LOSS), considerando i dati di validazione forniti dal dizionario
		chiama calc_f1() per calcolare le metriche F1 MICRO e F1 MACRO, utilizzando le etichette vere e le predizioni calcolate
		restituisce la perdita, f1 micro e macro e il tempo
	Funzione incremental_evaluate:
		imposta timer e inizializza le liste
		ciclo sui batch: 
			ottiene il dizionario, le etichette e un flag che indica se tutti i batch sono stati processati
			con sess_run() calcola le predizioni e la perdita (LOSS) su quel batch.
			continua fino a quando finished diventa true
		tutte le predizioni e le etichette vengono concatenate per avere un unico array
		viene usato calc_f1()
		resituisce la media deli LOSS, f1 micro e macro e il tempo impegato


TRAINING
Fase in cui il modello impara dai dati (un sottoinsieme del dataset complessivo). Per ogni esempio di training, il modello fa una previsione, e questa viene confrontata con l’etichetta reale (vero valore).
La loss calcolata indica quanto la previsione è lontana dal valore corretto.
Il modello aggiusta i pesi con l'ottimizzatore Adam per minimizzare l'errore per esempi futuri.
Il processo viene ripetuto su tutti i dati di training per un certo numero di epoche (cicli completi attraverso l'intero dataset).
L'obiettivo è fare in modo che il modello impari a fare buone previsioni sui dati di training, infatti man mano che il training prosegue, la loss dovrebbe diminuire, indicando che il modello sta imparando a minimizzare l'errore sui dati che ha visto finora.

VALIDAZIONE
Fase in cui misuriamo la performance del modello su un insieme di dati che non è utilizzato durante il training. Permette di valutare come il modello si comporta su dati che non ha mai visto.
Viene eseguita periodicamente durante il training (ogni x minibatch). 
L'obiettivo è prevenire l'overfitting (cioè quando il modello performa molto bene sui dati di training, ma male sui dati nuovi (validazione o test). E anche monitorare la generalizzazione, cioè quanto bene il modello generalizza i dati che non ha mai visto prima (minimizzare la loss).

TEST
Fase finale del ciclo di sviluppo di un modello che serve per valutare la performance finale del modello sui dati di test (diversi da quelli di training e di validazione). A differenza della fase di validazione, i dati di test non influenzano in alcun modo l'addestramento. Il risultato ottenuto sui dati di test rappresenta la misura finale della performance del modello.
Nel codice la fase di test è gestita nella funzione incremental_evaluate con il parametro test=True, che viene eseguita dopo aver completato tutte le epoche di training e di validazione.
La funzione incremental_evaluate valuta il modello in modo incrementale, batch per batch, fino a completare l'intero set di test.
Con incremental_node_val_feed_dict viene creato un sottoinsieme di nodi del test set alla volta, in modo tale da processare i nodi in piccoli batch. Ovviamente vengono scelti i nodi che precedentemente nel grafo sono stati definiti come "test".
	[In minibatch.py, nella classe NodeMinibatchIterator]: Per un determinato batch di nodi viene costruito il feed_dict (con la funzione batch_feed_dict), per fornire i dati al modello durante la fase di inferenza. Viene creato un elenco batch1 che converte ogni nodo in un indice tramite self.id2idx. Per ogni nodo nel batch viene generata la sua etichetta tramite _make_label_vec, creando una matrice in cui ogni riga rappresenta l'etichetta del nodo. (make_label_vec costruisce i vettori delle etichette (one-hot) per ogni nodo, prendendole dalla class_map che passiamo in input, controllando se è già una lista (per problemi multilabel), se no si costruisce un vettore di zeri pari al numero di classi).
Continuando con il funzionamento della funzione incremental_evaluate, per ogni batch vengono calcolare le predizioni (model.preds) e la loss (model.loss), e una volta che i batch sono terminati, le predizioni e le etichette reali (labels) vengono impilate in un'unica matrice, per calcolare le metriche finali di test. Poi si calcola f1.
La funzione restituisce la media delle perdite, i punteggi f1 e il tempo impiegato.
La test loss e le metriche (come l'F1-score) ottenute rappresentano il valore su cui puoi basare le tue decisioni per accettare o rifiutare il modello per l'uso pratico.
















	
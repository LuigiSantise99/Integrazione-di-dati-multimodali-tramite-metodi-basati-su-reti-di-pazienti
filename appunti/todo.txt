nuovo dataset: leggere paper e scaricare i nuovi dataset per l'addestramento del modello https://academic.oup.com/bioinformatics/article/40/9/btae523/7739700 
https://github.com/biomedicalinformaticsgroup/MOGDx/blob/main/R/data_download.R

parlare con la prof per capire come gestire il fatto che nei dati mancano delle viste comuni, nel senso magari una vista è presente in un pacchetto ma non lo è in un altro pacchetto (capire bene autonomamente prima cosa vuole dire tecnicamente)


vedere un po di teoria sulle nuove metriche
scrivere della teoria su sigmoide e softmax (https://towardsdatascience.com/sigmoid-and-softmax-functions-in-5-minutes-f516c80ea1f9)
models.py - riga 254 campionare
models.py - riga 278 aggregare
layers.py - riga 73 layer di predizione (ne parlo nel txt creazione modello e predizione)
	funzionamento aggregatori, riga 278 di models.py (ne parlo nel txt calcolo della loss)





sul git manca **MODIFICHE.md**, o comunque le modifiche al codice sia snf che graphsage

Nico: salvare in un file per ogni epoca le train loss e le val loss per convertirle in un grafico e capire se entrambe scendono. appena risalgono allora salvo l'epoca prima della risalita.




+togliere i dati methy durante la realizzazione di snf
+vedere il funzionamento della funzione calculate_n_components di snf
	-> prende il minore tra riga*proporzione e colonna*proporzione, quindi per RNASeq con una proporzione a 0.05 mi dava una dimensionalità troppo bassa quindi ho aumentato al 50%
	shape attuali per BLCA2:
	prima di RSVD (335, 470) (335, 12277) (335, 184)
	dopo RSVD     (335, 66)  (335, 166)   (335, 35)
+stratificazione degli split in inputFiles
	-> ho aggiunto i parametri shuffle e stratify, rispettivamente impostati a true e all'array che contiene tutte le etichette (che ho dovuto convertire in formato intero partendo da etichette one-hot, perchè la funzione non accettava le one-hot)
	nel primo split si prende l'array di etichette di tutto il set
	nel secondo split solo quello del training set
+modifica f1: ritorna solo un valore
	->  visto che come parametro usiamo 'binary' c'è bisogno che le etichette one-hot encoded vengano convertite in etichette intere (1, 0). Ho quindi modificato l'intero script per far funzionare la funzione calc_f1 con un unico output.
	-> I logits vicini a 0 indicano che il modello non è sicuro delle sue predizioni, risultando in probabilità vicine a 0.5.
+aggiungere il calcolo delle nuove metriche:
-recall
-precision
-specificity
per poi usare  AUPRC(x=recall y=precision) e AUC(x=recall y=1-specificity): https://stats.stackexchange.com/questions/338826/auprc-vs-auc-roc e metriche per la claffificazione python (su google)
X = FPR (1 - Specificity)
Y = TPR (Recall)
+fare primi grafici sulle metriche
	-> ora posso visualizzare l'andamento di tutte le metriche che il modello calcola, sia per la fase di training che per la fase di validation
	i grafi è meglio per ogni epoca o per ogni step, non sapendo però in che epoca ci troviamo


+vedere come escono i grafi visivamente (provare con un'altra env e quindi networkx aggiornato) -> escondo solo nodi attorno al nodo centrale
+capire anche perchè su G dell'example i links su train_removed e test_removed sono true mentre nei miei file tutti false -> perchè nessuno dei link è stato rimosso dal training set o dal test set

----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

scaricarare il dataset brca +

preprocessing di brca +
	cambiare informazioni cliniche da visualizzare (per i fenotipi? che indicano quali campioni rimuovere in base alle informazioni mancanti) +
							(fenotipi lasciati uguali all'originale)
	aggiungere seed 42 alla funzione cvTrait (dentro la funzione in preprocess_function) +
	knn +
	controllare sia il numero di pazienti che le features +
		il numero di features dei processati controllate aprendo il file Rdata su R (con load()) e per mRNA e miRNA controllare il numero di righe di datExp, per le altre il numero di colonne. Il numero di features degli estratti e il numero dei pazienti controllare la matrice (n x m) che esce fuori con knn, n->n_feature m->n_pazienti

poi usare i datexpr nel mio snf, delle omiche usate nella tabella del paper (quella evidenziata)
	
	

leggere paper di MOGONET e MoGCN: controllare se i risultati sono gli stessi o quelli di mogdx li hanno fatti rigirare (tabella 2)

label: paper grade (per lgg, invece per brca è l'altro mi pare quello con 50)

dati clinici: 

preprocessing: dat expr vanno presi solo i top genes


******************mandare email all prof casiraghi per capire se la laurea a febbraio è possibile


riordinare appunti in ordine di creazione - aggiungere numerino tipo capitoli
cambiare i requirements su github
sul git manca **MODIFICHE.md**, o comunque le modifiche al codice sia snf che graphsage
	snf: cercare 'modifiche' sul file versioneer.py





righe x colonne
miRNA: features x pazienti DA TRASPORRE
DNAm: pazienti x features
mRNA: features x pazienti DA TRASPORRE

devo estrapolare i topgenes (indici) dai dataexpr per poi usare snf. il numero di topgeni sono le feature estratte, il numero di righe di dataexpr sono invece le feature processate (per i mirNA, per dnam è il contrario). quindi l'idea è transporre le matrici che vanno transposte, andare a filtrare solo le features indicate dagli indici di topgene e poi usare snf. 
	problemi: se faccio una transposta, l'indice cambia? soluzione: per andare sul sicuro posso prima filtrare i topgene, per poi transporre la matrice
capire anche perchè nella shape le colonne vanno a +1, mentre le righe no

se uso già i topgeni, inutile fare rsvd?


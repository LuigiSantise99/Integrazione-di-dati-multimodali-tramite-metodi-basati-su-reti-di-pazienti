scaricarare il dataset brca +

preprocessing di brca +
	cambiare informazioni cliniche da visualizzare (per i fenotipi? che indicano quali campioni rimuovere in base alle informazioni mancanti) +
							(fenotipi lasciati uguali all'originale)
	aggiungere seed 42 alla funzione cvTrait (dentro la funzione in preprocess_function) +
	knn +
	controllare sia il numero di pazienti che le features +
		il numero di features dei processati controllate aprendo il file Rdata su R (con load()) e per mRNA e miRNA controllare il numero di righe di datExp, per le altre il numero di colonne. Il numero di features degli estratti e il numero dei pazienti controllare la matrice (n x m) che esce fuori con knn, n->n_feature m->n_pazienti
	
	righe x colonne 
miRNA: features x pazienti DA TRASPORRE
DNAm: pazienti x features
mRNA: features x pazienti DA TRASPORRE
	devo estrapolare i topgenes (indici) dai dataexpr per poi usare snf. il numero di topgeni sono le feature estratte, il numero di righe di dataexpr sono invece le feature processate (per i mirNA, per dnam è il contrario). quindi l'idea è transporre le matrici che vanno transposte, andare a filtrare solo le features indicate dagli indici di topgene e poi usare snf. 
	problemi: se faccio una transposta, l'indice cambia? soluzione: per andare sul sicuro posso prima filtrare i topgene, per poi transporre la matrice
capire anche perchè nella shape le colonne vanno a +1, mentre le righe no 
	poi usare i datexpr nel mio snf, delle omiche usate nella tabella del paper (quella evidenziata) +
	
	preprocessing: dat expr vanno presi solo i top genes +
		top genes: jessica: vengono calcolati con la differential expression e logistic regression
		per salvare il file txt dei topgenes ho usato questa riga: write.table(top_genes, "raw/top_genes.txt", row.names = FALSE, col.names = FALSE) # dopo aver load(.rds)
		se uso già i topgeni, inutile fare rsvd? 

	creazione dei dati di input: +
		innanzitutto ho unito i tre file meta mantenendo solo i pazienti in comune. -> sono 696 pazienti, il paper ne contava 698.
			L'altro numero (1083) considera tutti i pazienti e non solo quelli in comune nei tre file.
			devo far in modo che per ogni paziente salvi solo una volta le categorical column e la label, e non salvi le restanti colonne 
		filtrare e unire i file
		considerare l'attributo dell'età diviso in decade
		gestire gli NA -> nel file c'erano siano 'not reported' che 'nan', sono diventati tutti 'nan'. I valori vuoti diventeranno 'nan'
		codifica one hot sulle features. si creano molti elementi per via della features sull'età della diagniosi.
		codifica one hot delle label.
		creazione id map e class map
		creazione grafo g 
			controllato che ogni nodo abbia le giuste features e label +
			info da aggiungere alla tesi: 
			il codice esegue il training in modo trasduttivo. Questo significa che:

			Non crei due reti disgiunte per train e test:
			Tutti i nodi (inclusi quelli del test set) rimangono connessi nella stessa rete. Il grafo non viene suddiviso in due sottografi separati. In altre parole, i nodi nel 			test set possono essere vicini o connessi ai nodi nel train set.

			Divisione basata sulle label:
			Durante l'addestramento, il modello non utilizza le label dei nodi nel test set (i nodi con l'attributo test=True). Tuttavia, questi nodi rimangono parte del grafo e 			contribuiscono alla struttura topologica. I nodi di test possono influenzare l'addestramento del modello perché le informazioni di vicinato passano comunque 			attraverso di loro.

			L'attributo delle label nel test set:
			Nel test set, i nodi hanno ancora le loro etichette, ma queste non vengono utilizzate durante l'addestramento. Le label vengono utilizzate solo durante la fase di 			valutazione per calcolare le metriche.

			In breve: stai addestrando un modello trasduttivo, in cui:

			L'intero grafo (inclusi train, validation, e test) viene usato per costruire embedding dei nodi.
			Durante il training, solo i nodi del training set (non quelli di test) hanno le loro label visibili al modello.

			inoltre uso k-fold cv, con k=5
			info di jessica:
				https://scikit-learn.org/1.5/_images/grid_search_cross_validation.png
				lo si usa perchè lo usa anche mogdx, quindi per avere un confronto lineare e uguale
			
		

	usare graphsage:
		segnare anche le tempistiche
	
		prima cosa è come impostare ora le flag sul training supervisionato in modo efficiente. devo capire quali vengono usati su mogdx probabilmente, per prendere spunto
		cosa fare: su mogdx calcola 2 metriche: accuracy e f1_score. graphsage invece calcola la loss, l'f1 score micro e macro. la cosa più logica da fare per un confronto è andare a calcolare le stesse metriche di mogdx. 
		altra cosa che mi chiedo è: ma su mogdx, quei valori, si riferiscono a training, validazione o test? inoltre avendo cambiato i dati, vanno bene lo stesso le percentuali che uso per dividere questi set? -> ho cambiato per come vengono splittati su mogdx


		gestione degli archi pesati: 		
		creazione grafo g da mogdx con snf.to.graph (k impostato a 20 sia nella creazione della matrice di affinità, sia in mogdx)
			ho creato il grafo solo coi collegamenti con snf.to.graph di mogdx
			questo grafo devo convertirlo nel grafo che deve essere utilizzato da graphsage aggiungendo label, features (entrambi one hot) e poi le etichette per il val e test
				in graphsage-input-generator ho ordinato gli id in ordine alfabetico così da risultare coerente col grafo csv
			capire se e come rimuovere le colonne color dei grafi creati su mogdx

			

Totale di pazienti per ogni label:
Basal     104
Her2       43
LumA      394
LumB      125
Normal     30

matrice di confusione:
	Basal	Her2	LumA	LumB	Normal
Basal	20	1	0	0	0
Her2	0	9	0	0	0
LumA	1	0	78	0	0
LumB	0	1	23	1	0
Normal	1	2	3	0	0


stato dell'arte: altri lavori che fanno una cosa simili a quello che sto facendo io
		
	


leggere paper di MOGONET e MoGCN: controllare se i risultati sono gli stessi o quelli di mogdx li hanno fatti rigirare (tabella 2)

leggere file doc di jessica dove indica le criticità del preprocessing
capire se la libreria future è un problea durante l'adesramento, e i messaggi di warning quando snfpy in affinity-matrix.py


riordinare appunti in ordine di creazione - aggiungere numerino tipo capitoli
cambiare i requirements su github
sul git manca **MODIFICHE.md**, o comunque le modifiche al codice sia snf che graphsage che mogdx
	snf: cercare 'modifiche' sul file versioneer.py (sul server non è servito)
	utils (graphsage). riga 70
	anche su mogdx ci sono delle modifiche *****
		seed in cvtrait
		aggiunta funzione snf.to.graphfromPy
		vedere sotto secondo esperimento > snf.r
		modifiche knn_graph_generation.R per terzo esperimento, controllo range



primo esperimento:
	knn_graph_generation.R -> per avere datexpr e datmeta per ogni omica. 
	affinity_matrix.py -> prende datExpr generati nella pipeline di mogdx e crea la matrice di affinità fusa con snfpy con l'aggiunta degli id dei pazienti per ogni riga/col
	graph_creation.R -> prende la matrice di affinità con id appena creata e crea il grafo con i vari collegamenti tra nodi, usa snf.to.graph.FromPy
	graphsage_input_generator.py -> conversione grafo valido per graphsage + aggiunta feats, label e divisione in set + 5-fold cv (con features)
	addestrare modello supervisionato graphsage
	graphsage_input_generator.py -> conversione grafo valido per graphsage + aggiunta feats, label e divisione in set + 5-fold cv (senza features)
	addestrare modello supervisionato graphsage


secondo esperimento:
	knn_graph_generation.R -> per avere grafo, datexpr e datmeta per ogni omica. (i grafi vanno poi spostati nella cartella MOGDx/Network/SNF)
	SNF.R -> imposto modalities in base alle omiche che voglio considerare. Viene creato il grafo csv considerando la matrice di affinità fusa. (codice modificato per mantenere solo i pazienti in comune (696))
	graphsage_input_generator.py -> conversione grafo valido per graphsage + aggiunta feats, label e divisione in set + 5-fold cv (con features)
	addestrare modello supervisionato graphsage
	graphsage_input_generator.py -> conversione grafo valido per graphsage + aggiunta feats, label e divisione in set + 5-fold cv (senza features)
	addestrare modello supervisionato graphsage


TEST_1 (presentazione risultati primo e secondo esperimento)

- Iperparametri:
	+epoche: 50
	+dropout: 0.4
	+weight_decay: 0
	+learning_rate: 0.001
	+altre: 'model', 'graphsage_mean' 'max_degree', 128, , samples_1', 25, , samples_2', 25, , samples_3', 0, , dim_1', 128, , dim_2', 128, , random_context', True, , batch_size', 30, , 		sigmoid', False, identity_dim', 0, validate_iter', validate_batch_size', 64, gpu', 1,

RISULTATI PRIMO ESPERIMENTO (con features)

- ho usato la libreria snf di python (snfpy), per poi creare i collegamenti del grafo con snf.to.graph.FromPy, K=20, ho usato solo i top-genes
- Il grafo per graphsage è stato creato con la presenza di features
- metriche:
	+val -> loss=0.63810 f1_micro=0.78571 f1_macro=0.56649 f1_weighted=0.72933 accuracy_score=0.78571 AUPRC_score=0.72385 AUC_score=0.74741 time=0.02726
	+test -> loss=0.63533 f1_micro=0.75000 f1_macro=0.56245 f1_weighted=0.71279 accuracy_score=0.75000 AUPRC_score=0.60262 AUC_score=0.75211
- matrice di confusione (ordine label:	Basal	Her2	LumA	LumB	Normal):
[[20  0  1  0  0]
 [ 0  8  1  0  0]
 [ 1  0 71  6  1]
 [ 0  3 16  6  0]
 [ 1  2  3  0  0]]
- plot: loss1


RISULTATI PRIMO ESPERIMENTO (senza features)

- ho usato la libreria snf di python (snfpy), per poi creare i collegamenti del grafo con snf.to.graph.FromPy, K=20, ho usato solo i top-genes
- Il grafo per graphsage è stato creato senza la presenza di features, aggiungendo l'iperparametro --identity_dim 128
- metriche:
	+val -> loss=0.79734 f1_micro=0.79762 f1_macro=0.60728 f1_weighted=0.77086 accuracy_score=0.79762 AUPRC_score=0.73468 AUC_score=0.78235 time=0.05393
	+test -> loss=0.60911 f1_micro=0.79286 f1_macro=0.75134 f1_weighted=0.78571 accuracy_score=0.79286 AUPRC_score=0.77693 AUC_score=0.82820
- matrice di confusione (ordine label:	Basal	Her2	LumA	LumB	Normal):
 [[21  0  0  0  0]
 [ 0  6  1  1  1]
 [ 1  0 69  9  0]
 [ 0  0 14 11  0]
 [ 1  1  0  0  4]]
- plot: loss2



RISULTATI SECONDO ESPERIMENTO (con features)

- Ho generato il grafo con knn_graph_generation.R e ho usato l'snf fornita da mogdx (SNF.R), K=20, ho usato solo i top-genes
- Il grafo per graphsage è stato creato con la presenza di features
- metriche:
	+val -> loss=0.46396 f1_micro=0.86905 f1_macro=0.69525 f1_weighted=0.84116 accuracy_score=0.86905 AUPRC_score=0.82302 AUC_score=0.81222 time=0.04401
	+test -> loss=0.51694 f1_micro=0.81429 f1_macro=0.60740 f1_weighted=0.79670 accuracy_score=0.81429 AUPRC_score=0.73552 AUC_score=0.79202
- matrice di confusione (ordine label:	Basal	Her2	LumA	LumB	Normal):
 [[20  1  0  0  0]
 [ 0  7  1  1  0]
 [ 0  1 73  5  0]	
 [ 0  5  6 14  0]
 [ 2  1  3  0  0]]
- plot: loss3



RISULTATI SECONDO ESPERIMENTO (senza features)

- Ho generato il grafo con knn_graph_generation.R e ho usato l'snf fornita da mogdx (SNF.R), K=20, ho usato solo i top-genes
- Il grafo per graphsage è stato creato senza la presenza di features, aggiungendo l'iperparametro --identity_dim 128
- metriche:
	+val -> loss=0.44094 f1_micro=0.88095 f1_macro=0.80823 f1_weighted=0.88028 accuracy_score=0.88095 AUPRC_score=0.82656 AUC_score=0.89006 time=0.06273
	+test -> loss=0.53378 f1_micro=0.84286 f1_macro=0.72184 f1_weighted=0.83046 accuracy_score=0.84286 AUPRC_score=0.79949 AUC_score=0.82918
- matrice di confusione (ordine label:	Basal	Her2	LumA	LumB	Normal):
 [[20  1  0  0  0]
 [ 0  8  1  0  0]
 [ 0  0 73  6  0]
 [ 0  2  7 16  0]
 [ 1  0  4  0  1]]
- plot: loss4



con k=15 è peggiorato solo il secondo exp, il resto è piu o meno uguale (considerando le medie e le deviazioni standard avendo usato k fold cv)



terzo esperimento: (usando il preprocessing di mogdx che sparsifica sia le matrici singole che quella finale)
praticamente per ogni variabile in ogni dataset (mirna, mrna, dnam) bisogna calcolare la deviazione standard, per poi prendere le prime 500 con deviazione piu alta
il problema è che il range di queste variabili può cambiare quindi vanno convertite ad un range che sia uguale per tutti questa cosa però va fatta solo con mirna e mrna (fare un check per la dnam ma dovrebbe avere già tutti i range uguali (0-1)).
quindi prima vanno controllati i range:
	+ viene fatto su knn_graph_generation.R, La modalità DNAm ha i pazienti sulle righe, quindi va trasposta per essere coerente con miRNA e mRNA, di seguito i range globali per ogni omica:
	mRNA: Range globale:  2.979922 23.16517
	miRNA: Range globale:  2.298648 21.88383
	DNAm: Range globale:  0.004157793 0.9960434
	conclusioni: DNAm non va toccata perchè ha già range [0-1], mentre mRNA e miRNA va convertita per far si che abbia range [0-1]
	
per la conversione mi pare che volesse usare min-max la prof per il controllo. 
Dovevi fare il boxplot per miRNA ed mRNA di massimo per ogni feature, minimo per ogni feature e min-max per ogni feature. quindi 3 boxplot per mirna e 3 per mrna:
	+ nella cartella di mogdx c'è il file Rplots.pdf che contiente i 3 boxplot per ogni omica (anche dnam ho messo)

Ti rispiego quale è il problema: nel pre-processing di mogdx la feature selection viene fatta usando la differential expression o la regressione logistica multinomiale
per fare sia l'espressione differenziale che la regression logistica. tu devi fornire le etichette dei dati, loro le hanno fornite tutte, comprese quelle del test set
ora, è vero che il modello viene addestrato in modo trasduttivo (quindi il modello nel training vede tutti gli archi del grafo) ma non può vedere le etichette
se nella feature selection gliele fai vedere hai quello che viene chiamato information leakage. Cioè delle informazioni del test set sono scivolate all'interno dell'addestramento
e questo di solito porta a delle metriche di predizione over-ottimiche, cioè migliori di quanto dovrebbero essere
noi vogliamo vedere se il nostro modello regge anche senza questo bias, quindi ci aspettiamo un piccolo abbassamento delle performance
	+ ho modificato il file knn_graph_generation.R e aggiunto la funzione expr.to.graph.fs che normalizza e seleziona le feature con migliore deviazione standard
	expr.to.graph: prende i datExpr e li usa per calcolare le matrici di similarità e per sparsificarle


terzo esperimento:
	knn_graph_generation.R -> per avere grafo, datexpr e datmeta per ogni omica. (i grafi vanno poi spostati nella cartella MOGDx/Network/SNF). Diversamente dal secondo esperimento è stata modificato la funzione expr.to.graph per creare il grafo in maniera diversa 
	
	SNF.R -> imposto modalities in base alle omiche che voglio considerare. Viene creato il grafo csv considerando la matrice di affinità fusa. (codice modificato per mantenere solo i pazienti in comune (696))
	graphsage_input_generator.py -> conversione grafo valido per graphsage + aggiunta feats, label e divisione in set + 5-fold cv (con features)
	addestrare modello supervisionato graphsage
	graphsage_input_generator.py -> conversione grafo valido per graphsage + aggiunta feats, label e divisione in set + 5-fold cv (senza features)
	addestrare modello supervisionato graphsage

finito il terzo esperimento fare csv con:
	risultati dev standard exp1 con e senza features
	risultati dev standard exp2 con e senza features
	risultati dev standard exp3 con e senza features